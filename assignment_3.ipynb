{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DO NOT EDIT THIS FILE WITHIN THE /TSDS FOLDER - YOU RISK OVERWRITING YOUR WORK THE NEXT TIME YOU PULL FROM THE GITHUB REPOSITORY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "\n",
    "### Practical info\n",
    "* Handin in absalon. The deadline is the 23rd of April (see the [course plan](https://github.com/abjer/tsds/wiki/Course-plan))\n",
    "* You must work in groups of 2-4. **Remember to identify the group members in the filename or in the top of the file contents**.\n",
    "* If anything is unclear dont hesitate to email me at kuol@econ.ku.dk with questions.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Questions from exercise set 9 (Spatial #1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "import shapely\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init': 'epsg:4326'}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "b'no arguments in initialization list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-443f015ae293>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mkommuner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkommuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mkommuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epsg:25832'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mkommuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\geopandas\\geodataframe.py\u001b[0m in \u001b[0;36mto_crs\u001b[1;34m(self, crs, epsg, inplace)\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[0mgeom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\geopandas\\geoseries.py\u001b[0m in \u001b[0;36mto_crs\u001b[1;34m(self, crs, epsg)\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Must set either crs or epsg for output.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mproj_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyproj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m         \u001b[0mproj_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyproj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mproject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyproj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproj_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproj_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pyproj\\__init__.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(self, projparams, preserve_units, **kwargs)\u001b[0m\n",
      "\u001b[1;32m_proj.pyx\u001b[0m in \u001b[0;36m_proj.Proj.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: b'no arguments in initialization list'"
     ]
    }
   ],
   "source": [
    "# Run this code to get set up for exercise 9.2.2 - 9.2.5\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/ok-dk/dagi/master/geojson/kommuner.geojson\"\n",
    "kommuner = gpd.read_file(url)\n",
    "print(kommuner.crs)\n",
    "kommuner.to_crs('epsg:25832', inplace=True)\n",
    "kommuner.plot(figsize=(14,8))\n",
    "\n",
    "kommuner.columns = kommuner.columns.str.lower()\n",
    "    \n",
    "# information for municipality\n",
    "kommune_info = pd.read_json('https://dawa.aws.dk/kommuner')\\\n",
    "                .pipe(lambda df: \\\n",
    "                        df.assign(komkode=df.kode.astype(str).str.zfill(4)))\\\n",
    "                .loc[:,['komkode','regionskode']]\\\n",
    "                \n",
    "\n",
    "region_info = pd.read_json('https://dawa.aws.dk/regioner/')\\\n",
    "                .loc[:,['kode','navn']]\\\n",
    "                .add_prefix('regions')\n",
    "\n",
    "kommuner = kommuner\\\n",
    "                .merge(kommune_info,how='left')\\\n",
    "                .merge(region_info,how='left')\n",
    "\n",
    "\n",
    "dk_crs = {'ellps': 'GRS80', 'no_defs': True, 'proj': 'utm', 'units': 'm', 'zone': 32}\n",
    "def cell_coords_to_polygons(square_df, x='e', y='n', dist=500, crs=dk_crs):\n",
    "    '''\n",
    "    Convert coordinates to squares in a GeoDataFrame.\n",
    "       \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : str\n",
    "        Name of the horizontal coordinate (~longitude)            \n",
    "    y : str\n",
    "        Name of the vertical coordinate (~latitude)                        \n",
    "    dist : int or float\n",
    "        Size of polygons\n",
    "    crs : dict\n",
    "        Coordinate Reference System\n",
    "\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    squares_gdf: geopandas.GeoDataFrame\n",
    "        This table contains squares as geometry\n",
    "        and the original data.\n",
    "    '''\n",
    "    \n",
    "    def _to_square_polygon(row):\n",
    "        '''\n",
    "        This auxiliary function convert a square's lower,left \n",
    "        coordinates to a polygon. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        row : pandas.Series\n",
    "            This is a DataFrame row.            \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        poly: shapely.Polygon        \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        square_coords = ((row[x], row[y]), \n",
    "                         (row[x]+dist, row[y]), \n",
    "                         (row[x]+dist, row[y]+dist), \n",
    "                         (row[x], row[y]+dist))\n",
    "        \n",
    "        poly = shapely.geometry.Polygon(square_coords)\n",
    "        \n",
    "        return poly\n",
    "    \n",
    "    # convert to polygons\n",
    "    square_geoms = gpd.GeoSeries(square_df.apply(_to_square_polygon, axis=1), crs=crs)\n",
    "    \n",
    "    # make GeoDataFrame\n",
    "    square_gdf = gpd.GeoDataFrame(data=square_df, geometry=square_geoms)\n",
    "    \n",
    "    return square_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 9.2.2** Make two boolean series as follows. \n",
    " - first: row is True if corresponding the row shape is in the Capital Region or Sealand Region (i.e. `'Region Hovedstaden', 'Region Sjælland'`) \n",
    " - second: row is True if the  the row geometry is ***not*** in Bornholm or nearby (i.e. `'Bornholm', 'Christiansø'`)\n",
    "\n",
    "Finally make a combined series which takes the value True if both holds, otherwise False and use this series to select rows in the GeoDataFrame. \n",
    "\n",
    "> *Hint*: recall that we can check if a series elements are elements in a series using the `isin` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 9.2.2 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 9.2.3** Explain what is the CRS of the GeoDataFrame. How is distance measured using this coordinate system. Extract the extremum values (min,max) in all dimensions.\n",
    "\n",
    "> *Hint*: extreme values, i.e. bounds, can be found using `.bounds` on a GeoDataFrame (also works on shapes, GeoSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 9.2.3 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolation of house prices\n",
    "\n",
    "\n",
    "In the following two exercises we aim to compute local spatial neighborhood measures of house prices in Sealand and around. We do this by making make a grid of Sealand houseprice data. Thus the exercise will illustrate how to make a interpolation of data which is useful for feature engineering and get a good understanding of the data.\n",
    "\n",
    "**Ex. 9.2.4** We are now to construct a 500mx500m grid for Sealand:\n",
    "- Make a grid of points 500m apart in horizontal and vertical directions that are within the extremum values of Sealand's shape. \n",
    "- For each of these points construct a square polygon assuming that the point is the south west corner of the square. \n",
    "- Select all the house sales that take place within the Sealand and nearby islands.\n",
    "\n",
    "> *Hint 1:* Once you have created the grid the following function below may be useful for converting into a GeoDataFrame. You need to specify the column names for your x and y coordinates.\n",
    "\n",
    "> *Hint 2:* We can select the points that intersect by using a spatial join between the house locations and municipalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 9.2.4 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 9.2.5** Compute interpolation of house price for each grid cell as follows:\n",
    "- Load the pre-structured data with house sales prices for the capital region of Denmark\n",
    "- Make a loop over sale_year\n",
    "    - Fit a nearest neighbor regression model to the square meter price (i.e. `price_area` for each year)\n",
    "        - Set number of neighbors to 25 and radius to 25000\n",
    "    - Apply the model to the grid data and assign as a column\n",
    "- Plot the grid data for 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 9.2.5 here]\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "price_gdf = gdp.read_file('house_prices.geojson')\n",
    "price_gdf['n'] = price_gdf.geometry.y\n",
    "price_gdf['e'] = price_gdf.geometry.x\n",
    "\n",
    "knr = KNeighborsRegressor(n_neighbors=25, radius=25000)\n",
    "\n",
    "price_coord = price_gdf[(price_gdf.sale_year==2015)].dropna(subset=['sale_year', 'e', 'n', 'price_area'])\n",
    "\n",
    "price_nn = knr.fit(X=price_coord[['e', 'n']].values, y=price_coord.price_area.values)\n",
    "\n",
    "square_gdf_s['p'+str(2015)] = np.log10(price_nn.predict(square_gdf_s[['e', 'n']] + 250))\n",
    "\n",
    "square_gdf_s.plot(column='p2012', figsize=(6,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Questions from exercise set 10 (Spatial #2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely as shp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import statsmodels.formula.api as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# You need to download these files to get going. See the exercise set \n",
    "# for instructions.\n",
    "districts = gpd.read_file('data/school_districts_2017_2018.geojson')\n",
    "socioeco = gpd.read_file('data/socioeco_edited.geojson')\n",
    "school_perf = pd.read_csv('data/school_perf.csv')\n",
    "house_sales = gpd.read_file('data/sales.geojson')\n",
    "\n",
    "cph_map = gpd.read_file('data/cph_map.geojson').iloc[0,0]\n",
    "\n",
    "districts = districts[['skoleid','skolenavn','geometry']]\n",
    "house_sales = house_sales[house_sales['year']>2016]\n",
    "\n",
    "percs = house_sales['price_m2'].quantile([0.01,0.99])\n",
    "\n",
    "sales_dist_plt = plt.subplots(1,2,sharey=True,figsize=(12,4))\n",
    "sns.distplot(house_sales['price_m2'], ax=sales_dist_plt[1][0]) \n",
    "house_sales = house_sales[(percs[0.01]<house_sales['price_m2']) & (house_sales['price_m2']<percs[0.99])]\n",
    "sns.distplot(house_sales['price_m2'], ax=sales_dist_plt[1][1])\n",
    "sales_dist_plt[1][0].set_title('With outliers')\n",
    "sales_dist_plt[1][1].set_title('Without outliers')\n",
    "sales_dist_plt[0].suptitle('Distribution of square meter prices')\n",
    "plt.show()\n",
    "\n",
    "districts_perf = districts.merge(school_perf[school_perf['year']<2017].drop('year',axis=1).groupby('skolenavn',as_index=False).mean())\n",
    "\n",
    "socioeco_sub = socioeco\\\n",
    "    .loc[socioeco['aar']==2016,['rode_nr','geometry']]\\\n",
    "    .merge(socioeco[socioeco['aar']>2012]\\\n",
    "               .groupby('rode_nr',as_index=False)\\\n",
    "               .mean()\n",
    "          )\\\n",
    "    .drop('aar',axis=1)\n",
    "\n",
    "\n",
    "districts_perf_plt = plt.subplots(1,2,figsize=(18,8), gridspec_kw = {'width_ratios':[1,1.25]})\n",
    "districts.plot(color='lightgrey',edgecolor='black',ax=districts_perf_plt[1][0])\n",
    "districts.plot(color='lightgrey',edgecolor='black',ax=districts_perf_plt[1][1])\n",
    "districts_perf.plot(edgecolor='black',column='karsnit',legend=True,ax=districts_perf_plt[1][1])\n",
    "house_sales.plot(color='red', markersize=1,ax=districts_perf_plt[1][1])\n",
    "districts_perf_plt[1][0].set_axis_off()\n",
    "districts_perf_plt[1][1].set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 10.1.1**: *Border regions between school districts*.\n",
    " Make a function that finds the borders between the school districts given some specified border-width W. Make sure that your border building function satisfy the following constraints:\n",
    " - The borders should not intersect each other. There should be no borders between the school districts without any grade data and any other school districts. \n",
    " - Do not include borders between two school districts, if the district border coincides with a natural geographical border, such that the neighborhoods on each side of the geographical border are likely to be systematically different with regard to other variables than the school characteristics. For instance, it would be natural to exclude the Christianhavn school district from the analysis, since it is surrounded by the harbor and *Voldene*, and likewise it would be natural not to include the border between two school districts, if they are on different sides of the harbor. \n",
    "\n",
    " Compute the borders for the following border meter widths: 50, 100, 200, 300, 500. A border width of, for instance, 50 meters means that the computed border area should reach 25 meter into each district along the actual border:\n",
    "\n",
    "> **Hint**: One approach is to use a combination of the *buffer* and *overlay* function from *Geopandas* to construct the borders. Depending on your choice of method, the found borders will likely overlap, but you can then use *overlay* to find the overlap. After you have found the overlaps, you can use the *shapely* function *difference* to remove them. You can use a similar approach with the *cph_map* from above to remove borders between school districts on different sides of the harbor.\n",
    "\n",
    "> **Hint 2**: The borders produced should look like this.\n",
    "\n",
    "<img src=\"https://github.com/abjer/tsds/raw/master/material/10_spatial2/border_plt.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 10.1.1 here]\n",
    "\n",
    "\n",
    "# The school districts with no data \n",
    "schools = school_perf['skolenavn'].unique()\n",
    "no_perf_area = districts[~(districts['skolenavn'].isin(schools))]['geometry'].unary_union\n",
    "\n",
    "def make_borders(districts, border_width) :\n",
    "\n",
    "    \n",
    "\n",
    "    ################\n",
    "\n",
    "    # make borders #\n",
    "\n",
    "    ################\n",
    "\n",
    "    \n",
    "\n",
    "    # put buffer \n",
    "\n",
    "    buffer_dist = border_width / 2\n",
    "\n",
    "    districts['geometry'] = districts.buffer(buffer_dist)\n",
    "\n",
    "    \n",
    "\n",
    "    # make overlay\n",
    "\n",
    "    borders = gpd.overlay(districts,districts,how='intersection')\n",
    "\n",
    "    borders = borders[~(borders['geometry'].apply(lambda poly : poly.is_empty))]\n",
    "\n",
    "    borders = borders[borders['skoleid_1']!=borders['skoleid_2']]\n",
    "\n",
    "    \n",
    "\n",
    "    # name borders\n",
    "\n",
    "    borders['border_id'] = borders.apply(lambda row : sorted((row['skoleid_1'],row['skoleid_2'])),axis=1)\n",
    "\n",
    "    borders['border_id'] = borders['border_id'].apply(lambda border : '{0}-{1}'.format(border[0],border[1]))\n",
    "\n",
    "    borders = borders.drop_duplicates('border_id').reset_index(drop=True)\n",
    "\n",
    "    \n",
    "\n",
    "    #####################\n",
    "\n",
    "    # remove irrelevant #\n",
    "\n",
    "    #####################\n",
    "\n",
    "    \n",
    "\n",
    "    # conflicting border \n",
    "\n",
    "    conflict_b = gpd.overlay(borders[['border_id','geometry']],\n",
    "\n",
    "                             borders[['border_id','geometry']],\n",
    "\n",
    "                             how='intersection')\n",
    "\n",
    "    non_empty = pd.Series(~(conflict_b['geometry'].apply(lambda poly : poly.is_empty)))\n",
    "\n",
    "    has_conflict = conflict_b['border_id_1']!=conflict_b['border_id_2']      \n",
    "\n",
    "    conflict_b_uu = conflict_b[non_empty & has_conflict].geometry.unary_union\n",
    "\n",
    "        \n",
    "\n",
    "    # join with water \n",
    "\n",
    "    removal = shp.geometry.box(*cph_map.bounds).difference(cph_map).buffer(buffer_dist)    \n",
    "\n",
    "    removal = removal.union(conflict_b_uu).union(no_perf_area.buffer(buffer_dist))\n",
    "\n",
    "    \n",
    "\n",
    "    # apply removal \n",
    "\n",
    "    borders['geometry'] = borders['geometry'].apply(lambda border : border.difference(removal))\n",
    "\n",
    "    borders = borders[~(borders['geometry'].apply(lambda poly : poly.is_empty))]\n",
    "\n",
    "    \n",
    "\n",
    "    return borders.reset_index(drop=True)\n",
    "\n",
    "# Apply function\n",
    "border_widths = [50,100,150,200,300,500]\n",
    "remove_chr_havn = districts_perf['skolenavn']!='Christianshavns Skole'\n",
    "# removal, conflict_b_uu, no_perf_area, buffer_dist = make_borders(districts_perf[remove_chr_havn].copy(),50)\n",
    "borders = [make_borders(districts_perf[remove_chr_havn].copy(),d) for d in border_widths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 10.1.2**: Do the following\n",
    "  1. Merge the residential sales with the school districts and socioeconomic data based on the coordinates of the sale and the school districts and rode areas (CPH municapality's spatial cells). \n",
    "  2. Find the residential sales located within the sets of borders for the different border widths. \n",
    "  3. Plot the located within the border sets for the different border widths.\n",
    "\n",
    "> **Hint**: Recall the `sjoin` function from `geopandas` may be of help.\n",
    "\n",
    "The selected houses within borders should look like:\n",
    "\n",
    "<img src=\"https://github.com/abjer/tsds/raw/master/material/10_spatial2/border_sales_plt.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 10.1.2 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Ex 10.1.3**:  Run a linear regression of the effect of schools' grade average on square meter prices, where you control for the size of the sold property and relevant socioeconomic properties of the neighborhood. We have used percent of non-western immigrants and descendants, low income, non-educated and high school educated as our socioeconomic variables, but you can play around with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 10.1.3 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Ex 10.1.4**:  For each border width now try to run a linear regression of the effect of schools' average grade on square meter prices, where you only use the sales within the borders and control for residential area, socioeconomic neighborhood properties and border fixed effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 10.1.4 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Ex 10.1.5**:  Compare the estimated effect from the controlled linear regression on all sales with the estimated effects from the linear regressions on the different border sets. The figure below show a summary of the results, we get from our analysis. The blue lines are confidence intervals of the effect of schools' average grade on house prices estimated with the different border sets (we do not use clustering). The grey area shows the confidence interval from the controlled linear regression model on all the sales.\n",
    "\n",
    "<img src=\"https://github.com/abjer/tsds/raw/master/material/10_spatial2/results_fig.png\">\n",
    "\n",
    " Would you say that the results suggest that there is a causal effect of the local shool's average grade on square meter price? Would you have expected that the estimated effect declines, when borders of greater width are used to estimate it? If not, what could explain that we this? Investigate your hypothesis, if you have time  for it (and tell us, if you find something interesting).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Answer to ex. 10.1.5 here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* We see that estimates using border fixed effects are all below the confidence interval of the cross sectional analysis. This indicates that the cross-section analysis is biased. We see that for larger border the effect vanishes - see next questions for possible explanations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
